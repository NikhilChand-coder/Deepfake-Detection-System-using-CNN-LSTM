{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e37f7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.applications import Xception\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6aab7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "DATA_DIR = 'Dataset'\n",
    "\n",
    "VID_DIR = os.path.join(DATA_DIR, 'Videos')\n",
    "\n",
    "IMG_SIZE = (299, 299)\n",
    "FRAMES = 10\n",
    "\n",
    "BATCH_SIZE_VID = 2\n",
    "\n",
    "EPOCHS_VID = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36bee39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Video Frame Generator (batch streaming)\n",
    "def sample_video_frames(video_path, num_frames=FRAMES):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    idxs = np.linspace(0, total - 1, num_frames).astype(int)\n",
    "\n",
    "    for i in range(total):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i in idxs:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, IMG_SIZE)\n",
    "            frames.append(frame / 255.0)\n",
    "    cap.release()\n",
    "\n",
    "    while len(frames) < num_frames:\n",
    "        frames.append(frames[-1])\n",
    "    return np.array(frames)\n",
    "\n",
    "def video_generator(video_root, batch_size=BATCH_SIZE_VID):\n",
    "    classes = ['real', 'fake']\n",
    "    video_paths, labels = [], []\n",
    "    for idx, cls in enumerate(classes):\n",
    "        folder = os.path.join(video_root, cls)\n",
    "        for f in os.listdir(folder):\n",
    "            video_paths.append(os.path.join(folder, f))\n",
    "            labels.append(idx)\n",
    "\n",
    "    while True:\n",
    "        idxs = np.random.permutation(len(video_paths))\n",
    "        for i in range(0, len(idxs), batch_size):\n",
    "            batch_idx = idxs[i:i+batch_size]\n",
    "            batch_videos, batch_labels = [], []\n",
    "            for j in batch_idx:\n",
    "                try:\n",
    "                    frames = sample_video_frames(video_paths[j])\n",
    "                    batch_videos.append(frames)\n",
    "                    batch_labels.append(labels[j])\n",
    "                except:\n",
    "                    continue\n",
    "            yield np.array(batch_videos, dtype=np.float32), np.array(batch_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a62bcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Xception+LSTM Video Model...\n",
      "Epoch 1/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - accuracy: 0.4044 - loss: 0.7664 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1982s\u001b[0m 20s/step - accuracy: 0.4450 - loss: 0.7381 - val_accuracy: 0.4800 - val_loss: 0.6920\n",
      "Epoch 2/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1617s\u001b[0m 16s/step - accuracy: 0.4900 - loss: 0.7040 - val_accuracy: 0.4600 - val_loss: 0.6938\n",
      "Epoch 3/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - accuracy: 0.5097 - loss: 0.6950 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1659s\u001b[0m 17s/step - accuracy: 0.5050 - loss: 0.7055 - val_accuracy: 0.5000 - val_loss: 0.6856\n",
      "Epoch 4/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2516s\u001b[0m 25s/step - accuracy: 0.4850 - loss: 0.7142 - val_accuracy: 0.4200 - val_loss: 0.7039\n",
      "Epoch 5/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16s/step - accuracy: 0.6055 - loss: 0.6781 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1896s\u001b[0m 19s/step - accuracy: 0.6050 - loss: 0.6696 - val_accuracy: 0.7000 - val_loss: 0.6149\n",
      "Epoch 6/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1458s\u001b[0m 15s/step - accuracy: 0.5400 - loss: 0.6854 - val_accuracy: 0.5400 - val_loss: 0.6578\n",
      "Epoch 7/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - accuracy: 0.6422 - loss: 0.6508 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1417s\u001b[0m 14s/step - accuracy: 0.6600 - loss: 0.6457 - val_accuracy: 0.8000 - val_loss: 0.5423\n",
      "Epoch 8/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1696s\u001b[0m 17s/step - accuracy: 0.5950 - loss: 0.6559 - val_accuracy: 0.7000 - val_loss: 0.6094\n",
      "Epoch 9/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1611s\u001b[0m 16s/step - accuracy: 0.6450 - loss: 0.5966 - val_accuracy: 0.7400 - val_loss: 0.5461\n",
      "Epoch 10/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1632s\u001b[0m 16s/step - accuracy: 0.6350 - loss: 0.6394 - val_accuracy: 0.6800 - val_loss: 0.5606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------------------------------------------\n",
    "# Video Model (Xception + LSTM)\n",
    "frame_cnn = Xception(include_top=False, input_shape=(299, 299, 3), pooling='avg', weights='imagenet')\n",
    "frame_cnn.trainable = False\n",
    "\n",
    "model_vid = models.Sequential([\n",
    "    layers.TimeDistributed(frame_cnn, input_shape=(FRAMES, 299, 299, 3)),\n",
    "    layers.LSTM(128),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(1, activation='sigmoid', dtype='float32')\n",
    "])\n",
    "\n",
    "model_vid.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "callbacks_vid = [\n",
    "    callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    callbacks.ModelCheckpoint('saved_models/best_video_model_xception.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Train Video Model (batch generator)\n",
    "train_gen_vid = video_generator(os.path.join(VID_DIR), BATCH_SIZE_VID)\n",
    "val_gen_vid = video_generator(os.path.join(VID_DIR), BATCH_SIZE_VID)\n",
    "\n",
    "steps_train = sum([len(files) for r, d, files in os.walk(os.path.join(VID_DIR, 'real'))]) // BATCH_SIZE_VID\n",
    "steps_val = steps_train // 4 \n",
    "\n",
    "print(\"\\nTraining Xception+LSTM Video Model...\")\n",
    "history_vid = model_vid.fit(\n",
    "    train_gen_vid,\n",
    "    validation_data=val_gen_vid,\n",
    "    steps_per_epoch=steps_train,\n",
    "    validation_steps=steps_val,\n",
    "    epochs=EPOCHS_VID,\n",
    "    callbacks=callbacks_vid,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_vid.save('saved_models/final_video_deepfake_model_xception.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44a76f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating video model...\n",
      "\n",
      "Starting evaluation...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAGJCAYAAAB8RgPQAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAALoFJREFUeJzt3Qd8FGX6B/Dn3UAaJZRAEnoH6VVEpAkC6iHFiiIgCIcHSEdzitIkCp70oh5d4bAcoMiB9ICCUgwIKkeJIr0nJJgQkvl/ntf/7O0um7CbbLKZ9/19/YxhZ2d3ZrY88+wzz8wIwzAMAgAAS7L5ewEAACD7EMQBACwMQRwAwMIQxAEALAxBHADAwhDEAQAsDEEcAMDCEMQBACwMQRwAwMIQxH3k2LFj1LFjRwoLCyMhBK1Zs4Z86ddff5XPu2TJEp8+r5W1bdtWDvldpUqVqG/fvnedjt9bfo/5vdZFTt5DT19X1SkVxE+cOEF//etfqUqVKhQcHExFixalli1b0syZM+mPP/7I1Xn36dOHfvzxR3rrrbdo+fLl1LRpU1IFf1E4uPDr6e515A0Y38/Du+++6/Xznz17lsaPH09xcXGU3x04cECu5+uvv57pNObrMXLkSLICM0HgYfLkyW6nee655+T9hQsXzvPlg6wVIEV89dVX9OSTT1JQUBD17t2b6tatS7du3aJdu3bRmDFj6MiRI/TBBx/kyrw5sO3evZtee+01GjJkSK7Mo2LFinI+BQsWJH8oUKAA3bx5k7788kt66qmnnO77+OOP5UYzJSUlW8/NQXzChAkys2rYsKHHj/v6668przVu3Jhq1apFK1euzDTgrVixQv7t1auX/Hv06FGy2fJ/vsTvIa+X6wYqOTmZ1q5dK++H/Cf/f7I8EB8fT88884wMdD/99JPMvAcMGECDBw+WH0oeV6dOnVyb/6VLl+TfYsWK5do8OAviL1FAQAD5A28c27dvL19Pd0Hr0UcfzbNl4Y0JCwwMlENe46z05MmTtGfPHrf382vEgZ4Dvvna+Wvj641HHnlEflcOHjzoNJ4DOCdEDz30kN+WDRQP4lOnTqWkpCRauHAhRUVF3XF/tWrVaNiwYfbbt2/fpkmTJlHVqlXlF4wzwL///e+Umprq9Dge/5e//EVm8/fee68MolyqWbZsmX0aLgPwxoNxxs/Blh9nliHMfzvix/B0jjZt2kQPPPCA3BDwT9aaNWvKZbpbTXzr1q3UqlUrKlSokHxs165d6eeff3Y7v+PHj8tl4um4dv/CCy/YA6Innn32WfrPf/5D169ft4/bu3evLB/wfa6uXr1Ko0ePpnr16sl14nLMww8/7BQktm/fTs2aNZP/5uUxf9ab68n1Uv5VtX//fmrdujWFhobaXxfXeiqXtPg9cl3/Tp06UfHixWXG76sg7phxO+Ll5MzbnCaz2i3/MnzwwQcpJCSEypUrJ7P6jIwMt/Pj19x8j4sUKSI3mPx4V558FrLSokULqly58h3rxb+0OnfuTCVKlHD7uHnz5skkib9LZcqUkcmT42fExL+E+TvH68zfp507d7p9Pv4evvnmm/J7y89Zvnx5Gjt27B3fT/h/hgLKli1rVKlSxePp+/Tpw6ffNZ544glj7ty5Ru/eveXtbt26OU1XsWJFo2bNmkZERITx97//3ZgzZ47RuHFjQwhhHD58WE5z8OBBY/r06fLxPXv2NJYvX26sXr3aPh9+DldvvvmmnN7EzxUYGGg0bdrUmDlzprFgwQJj9OjRRuvWre3TxMfHy8csXrzYPm7Tpk1GgQIFjBo1ahhTp041JkyYYISHhxvFixeX07vOr1GjRkaPHj2MefPmGS+++KIcN3bsWI9er0KFChmJiYlGcHCwsXDhQvt9w4cPN2rVqmVfvmnTptnv27t3r1G1alXj1VdfNd5//31j4sSJ8r0KCwszzpw5I6c5f/68HM+PHThwoHz9eDhx4oS8v02bNkZkZKRRqlQpY+jQofJ51qxZY7+PB9O1a9eMcuXKGc2aNTNu374tx/Fryc/Nz+lL999/v/xcmPMxjRw5Us7PXH7GnwF+DU3nzp2T68Pv0/jx4+VrVr16daN+/frysY7v3bJly+TnrXPnzsbs2bONd955x6hUqZJRrFgxp+k8/Sy44/je8ee8QoUKRkZGhrzv0qVL8nlXrlxp/xw4Mj9bHTp0kMs3ZMgQIyAgQL4Ht27dsk/3z3/+U07Hr9usWbPk54bXgb+3ju9henq60bFjRyM0NFROw+83PycvQ9euXZ3m7fq66sryQTwhIUF+OFzf4MzExcXJ6TmIOeKgyeO3bt3q9CHhcbGxsfZxFy9eNIKCgoxRo0bZx7kLYN4EcXMjwF+YzLgL4g0bNjRKly5tXLlyxT6ONyo2m01umFzn169fP6fn7N69u1GyZMlM5+m4HuaXlzd87du3t3/hOMBywHD3GqSkpMhpXNeDXz8O3I7B3nXdTPwF5/s4GLu7zzEAsI0bN8rpJ0+ebJw8edIoXLjwHRtnX+CNP8+H52fideWNVIsWLbIMNhyc+LHfffed0+eKN26OQfzGjRsy0A0YMMDp+XjDx9M6jvf0s+CO43vHCQX/e+fOnfb15NcwOTn5jiDOy8zJBwddx/eZkx1+jkWLFsnbHMx52XgZU1NT7dN98MEHcjrH95A3trzM5vxN5sb4m2++yfR11ZXlyymJiYnyL//M9MT69evlX9fOgVGjRtl3kDqqXbu2/IlqKlWqlCx1cE3UV8xaOtceM/tJ7ercuXOym4N/pjv+zK1fv76sXZrr6WjQoEFOt3m9rly5Yn8NPcFlEy6BnD9/Xv5857/uSimMfwqbO/TS09PlvMxSEXd5eIqfh0stnuA2T+5QmjhxIvXo0UOWV95//33ytaefflrWuR1LDzt27KAzZ844lVLc4ffmvvvukyUFx8+V6+O4xMZliZ49e9Lly5ftA+8Xad68OW3bti3bn4XMcFmEH2fu++D147IMl7Fcbd68WdbKhw8f7rTjlvdHcenM/C7t27ePLl68KD9/jvsweHm5rOfo008/pXvuuUfuU3BcZy49MXOd4X8sH8T5w8Ju3Ljh0fS//fab/MBxvc1RZGSkDKZ8v6MKFSrc8RxcX7127Rr5MiBwK+SLL75IERERciftJ598kmVAN5eTA6Ir/hLwB5+7CrJaF14P5s268M4v3mCuWrVK1kq5nu36Wpp4+adPn07Vq1eXgTg8PFwGq0OHDlFCQoLH8yxbtqxXOzC5zZGDGQe2WbNmUenSpT3aOc0bJHPgfSxZKVmypKy1r1692t6VwwGPu3hcu3fcvXf8mrhyfS95XwPjAMavm+PAnTkcGM3nc/f4rD4LWeGNMgdT3ofy7bffZrqRzmy+/F7xviPzfvOv6zrzRpCnc11nrve7rm+NGjXk/eY6g0IthhzEeWfK4cOHvXqc647FzGTWDeLJVe0ymwdnpY54R09sbKzMMjh72bBhgwyS/OXlL6uvOlJysi4mDsac4S5dulT+GuGdppmZMmUKjRs3jvr16yd3JHNg5Q0oZ26e/uIwXx9v/PDDD/YvO/fucyZ7N7wxctyA8461rNbNbCFct26dHB577DH6/PPP5S8BDjq+YL5GfNwBJxmueIORG/j1io6Olhk1b6x4nfIKrzPvCH/vvffc3s87OUGxIM64g4T3fHOvNu9hzwp3kvAHhbf4nKWYLly4IH+6mp0mvsCZrru99K7ZPuPgxi18PPAHmAMg951zYO/QoYPb9WDcCeHql19+kVkvdynkBs7MFi1aJJeZfzVk5rPPPqN27drJriFH/Jrw8nm7QfUEZ5xceuEy2P333y87l7p3727vgMkM/6pwPJDJNUN0hwM3/yrhDJyzSv5Fc7dSivnemVm2I9f3kjs5GP+ScPcZcHw+d4/P7meBf7HxL0Mum7300kuZbiwc5+v4enGJhdt+zWU2p+N1NssiLC0tTU7XoEEDp3Xm7iX+Hvjyc6Eyy5dTGLcf8YeUyxEcjN0dycm942Y5gM2YMcNpGnPL78t+Z/5ActmAywcmrl/yT3DXVjxX5kEvmbVVcSslT8MZseOGgn+RcPZurmdu4MDMmfWcOXPcZoiOmb9rls8/07lu7MgMMO42eN565ZVX6NSpU/J14feU2/u49fBu7WkctDjomIMnQZx/IfAGgmvO8+fPl+vB9eO74feGe8y///57p3IOb0gccbmGf2nyBp0DXmbHJ+TGZ4FbHvnXyNChQzOdhl8nLp1wycrxfeaNNn/uze8SH73Mv04WLFggA7yJ20hd33MuRfHn48MPP7xjfryR9aYspAslMnEOlpwNcW2Zs2vHIza5pseBw+zT5a0+f6k5c+cPUJs2beSXib8A3bp1kwHKVzhL5aDCX/SXX35Z9mTzl53re4479ngnHJdT+EPPWQuXArj3lvuHuXc8M9OmTZN91/zro3///vJDPnv2bLmz6G6lgJzgDDyrw84dfyHxunFmzFkxlzY4ULkGSH7/eH8Ef8k5s+VgyDvuuGfZG7yjlV83Dj7mgTaLFy+WveRc1uGs3Ne4pMLHDWzcuFFm4Z5kvJx0cImEe6/5+AV+DH8e+b133OBzAOfPy/PPPy/Xhz9PHAx5I8VlN97w8IY0Nz4L/L3gISu8LFx24aNteV34lwln5fwe8C8f84hV/pXCGwXe4cyZOH9POQPn98b1s8DryvuDeCco/wrldeTyI/+i4PH8Oqt0SgufMBTy3//+V7ZdcR8ttz4VKVLEaNmypexf5XY3U1pammyLq1y5slGwYEGjfPnyRnR0tNM0ZgvTo48+etfWtsxaDNnXX39t1K1bVy4P95x/9NFHd7QYbtmyRbZIlilTRk7Hf7nnnNfHdR6ubXibN2+W6xgSEmIULVrU6NKli/HTTz85TWPOz7WFkZ/LtS/ZHXf9wa4yazHkVsyoqCi5fLycu3fvdtsauHbtWqN27dqyH9hxPXm6OnXquJ2n4/NwDzu/X9zHz++voxEjRsi2NZ63r3GfOK8fL/P69evdTuOuFe7QoUNy2bnvntsSJ02aJPvv3b0f27ZtMzp16iTbCnl67r3v27evsW/fPq8/C+5k9fn15HPALYV8rAB/l7h3/qWXXpI9+674+AT+znGLKR8Twa277j4L3JLI/fD8vvO03OvepEkT+Z3llmITWgz/JPh/vtkcAABAXlOiJg4AoCsEcQAAC0MQBwCwMARxAAALQxAHALAwBHEAAAtDEAcAsDAljth0NeAT706GBdZ24487D0kHdf2rT6McPT6kUfavg/vHD38eIZufKBnEAQAyJdQqQCCIA4BehFpnR0QQBwC9CLUycbXWBgBAM8jEAUAvAuUUAADrEmoVIJCJA4BeBDJxAADrEsjEAQCsS6iViau1SQIA0Axq4gCgF6FW7oogDgB6EWqVUxDEAUAvApk4AIB1CWTiAADWJdTKxNVaGwAAzaAmDgB6EWrlrgjiAKAXG2riAADWJdTKxNVaGwAAT7pTsjt4ISYmhpo1a0ZFihSh0qVLU7du3ejo0aNO07Rt25aEEE7DoEGDvJoPgjgA6JeJi2wOXtixYwcNHjyY9uzZQ5s2baK0tDTq2LEjJScnO003YMAAOnfunH2YOnWqV/NBTRwAIBds2LDB6faSJUtkRr5//35q3bq1fXxoaChFRkZmez7IxAFALyL75ZTU1FRKTEx0GnicJxISEuTfEiVKOI3/+OOPKTw8nOrWrUvR0dF08+ZNr1YHQRwA9CKyX07hOndYWJjTwOPuJiMjg4YPH04tW7aUwdr07LPP0kcffUTbtm2TAXz58uXUq1cvr1YH5RQA0IvIfoshB9qRI0c6jQsKCrrr47g2fvjwYdq1a5fT+IEDB9r/Xa9ePYqKiqL27dvTiRMnqGrVqh4tE4I4AOhFZL8AwQHbk6DtaMiQIbRu3TqKjY2lcuXKZTlt8+bN5d/jx48jiAMA+PMEWIZh0NChQ2n16tW0fft2qly58l0fExcXJ/9yRu4pZOIAALmASygrVqygtWvXyl7x8+fPy/FcRw8JCZElE77/kUceoZIlS9KhQ4doxIgRsnOlfv36Hs8HQRwA9CLypp9j/vz59gN6HC1evJj69u1LgYGBtHnzZpoxY4bsHS9fvjw9/vjj9Prrr3s1HwRxANCLyLtySlY4aPMBQTmFIA4AehFqdVYjiAOAXgSCOACAdQm1TkWr1iYJAEAzKKcAgF6EWrkrgjgA6EWoVU5BEAcAvQhk4gAA1iWQiQMAWJZQLIir9bsCAEAzqIkDgFaEYpk4gjgA6EWQUhDEAUArApk4AIB1CQRxAADrEooFcXSnAABYGGriAKAVoVgmjiAOAHoRpBQEcQDQikAmDgBgXQJBHADAuoRiQRzdKQAAFoaaOABoRSiWiSOIA4BeBCkFQRwAtCKQiQMAWJdAEAcAsC6hWBBHdwoAgIWhJg4AehGkFARxANCKUKycgiAOAFoRCOIAANYlEMQBAKxLKBbE0Z0CAGBhqIkDgF4EKQVBHAC0IhQrpyCIA4BWBII4AIB1CcWCOHZsAgBYGMopAKAXQUpBELeY6uGh1KlWOFUsHkLFQgrS3F2/UdzZG/b7X2hWlu6vXNzpMYfP3aCZO3/zw9JCTtWKKERd6kRQ5ZKhVCK0IL279STt+z3BaZoyYUH0bJOyVDuiMNkE0ZmEFHpvezxdSU7DG6BBOQVB3GKCCtjo9PUU+ib+Gv2tZUW30/x47gYt2XvGfvt2ekYeLiH4UnCBAPrt2h+0/fgVGtWuyh33RxQJpAmda9C241fos7hz9EdaOpUrFkxp6QbeiEwgiINfHT6fJIes3M4wKDHldp4tE+SeuDOJcsjM043KyPtX7D9rH3fhxi28JVlAEId8r2apQvSPx2rRzVvp9MvFJFpz+CIl30r392KBj3FRoFG5ovTl4QsU3aEqVSoRQpeSbtGaHy/cUXKB/0EQ96HLly/TokWLaPfu3XT+/Hk5LjIyku6//37q27cvlSpVypez0wJn6QfOJNLl5FtUqlAgda8XQcNaVaSYrSfJwC9spRQNLkAhBQPosboR9EncOZmNNyhblEa2q0yTNh6nny9k/YsN1OC3mvjevXupU6dOFBoaSh06dKAaNWrI8RcuXKBZs2bR22+/TRs3bqSmTZtm+TypqalycJSedosCCgaSjvY6ZGBnElLpdEIKxTxaU2bnv1xM9uuygW/xTky2//cEWv/TJflvrp/XKF2IOtQMRxDPjFr7Nf0XxIcOHUpPPvkkLViw4I6fN4Zh0KBBg+Q0nKVnJSYmhiZMmOA0rtETL1GTJ/+WK8ttNZeT0+hGym0qXTgQQVwxianpcv8Hb6gdnb2eQjUjCvltufI7oVh3it8O9jl48CCNGDHC7QvK4/i+uLi4uz5PdHQ0JSQkOA0Nu72YS0ttPcVDClChoABKwI5O5aRnGHTycjKVKRrsND4yLIguJ2HnZmY4vmR3yI/8lolz7fv777+nWrVqub2f74uIiLjr8wQFBcnBkcqlFG4x5KzaFF44kMoXC5Y7LnnoUrsUHTidKIN2qcKB9ET9SLmz68hdOlog/77fkUX+9/kuXSRQHiOQdOu27AP/8shFGta6kiydHDl/gxqWLUpNyoXRxI3H/Lrc+ZnIn7HYekF89OjRNHDgQNq/fz+1b9/eHrC5Jr5lyxb68MMP6d133/XX4uVb/AUe066y/fbTDaPk32/jr9FHB87KHuEWlYpTaEEbXU+5TT+d5+6UC/JnN1hP1ZKh9Ebn6vbbvZuVk393HL9C8785RXtPJdA/9/xOXetFUN97y9HZxD8P9DmK/R+Zyq8ZdXYJgwvQfrJq1SqaPn26DOTp6X+2wAUEBFCTJk1o5MiR9NRTT2XreQd8ctjHSwr52Y0/cGSiTv7Vp1GOHl99zIZsP/bYtM6U3/j1BFhPP/007dmzh27evElnzpyRA/+bx2U3gAMAZIUT8ewO3uCmi2bNmlGRIkWodOnS1K1bNzp69KjTNCkpKTR48GAqWbIkFS5cmB5//HFZjbDcWQwLFixIUVFRcuB/AwBYfcfmjh07ZIDmpHTTpk2UlpZGHTt2pOTk/7X6cgPHl19+SZ9++qmc/uzZs9SjRw+v5oNzpwCAVkQelcQ3bHAu2yxZskRm5Fw+bt26teykW7hwIa1YsYIefPBBOc3ixYvpnnvukYH/vvvu82g+COIAoBWbeZRUNrg7uNBdh5w7HLRZiRIl5F8O5pyd88GOJu7Wq1Chgjw+xtMgni/KKQAAVqiJx8TEUFhYmNPA4+4mIyODhg8fTi1btqS6devKcXyqkcDAQCpWrJjTtNypZ56GxBPIxAEAPMQHF3LnnCNPsnCujR8+fJh27dpFvoYgDgBaETkointaOnE0ZMgQWrduHcXGxlK5cn/2+ZsHPN66dYuuX7/ulI1zdwrf5ymUUwBAKyKPWgz5EBwO4KtXr6atW7dS5cr/O0iP8fEw3I3HBzeauAXx1KlT1KJFC4/ng0wcALQi8qg9hUso3Hmydu1a2Stu1rm5jh4SEiL/9u/fX5ZneGdn0aJF5Un/OIB7ulOTIYgDgFZEHgXx+fPny79t27Z1Gs9thHy9BMZHrNtsNnmQD3e98Om5582b59V8EMQBQCsij/rEPTmjSXBwMM2dO1cO2YWaOACAhSETBwCtCMXOYoggDgBaEWrFcARxANCLUCyKIxMHAK0ItWI4gjgA6EUoFsXRnQIAYGEopwCAVoRaiTiCOADoRSgWxZGJA4BWhFoxHEEcAPQiFIviyMQBQCtCrRiO7hQAACtDJg4AWhGKpeII4gCgFaFWDEcQBwC9CMWiODJxANCKQBAHALAuoVYiju4UAAArQzkFALQiFEvFEcQBQCtCrRiOIA4AehGKRXFk4gCgFaFWDEcQBwC92BSL4riyDwCAhaGcAgBaEWol4gjiAKAXoVgURyYOAFqxqRXDEcQBQC8CmTgAgHUJxTJxdKcAAFgYauIAoBVBaqXiCOIAoBWbWjEcQRwA9CIUK4ojEwcArQi1YjiCOADoxaZYFEd3CgCAhaGcAgBaEWol4gjiAKAXoVgURyYOAFoRasVwBHEA0ItNsSiOTBwAtCJILehOAQCwMGTiAKAVgXIKAIB12RSrpyATBwCtCGTiAADWJZCJAwBYl1AsimerO2Xnzp3Uq1cvatGiBZ05c0aOW758Oe3atcvXywcAAL4M4p9//jl16tSJQkJC6IcffqDU1FQ5PiEhgaZMmeLt0wEA5PmOTVs2ByWC+OTJk2nBggX04YcfUsGCBe3jW7ZsSQcOHPD18gEA+LycIrI5KBHEjx49Sq1bt75jfFhYGF2/ft1XywUAkCtEDgZvxMbGUpcuXahMmTJyA7BmzRqn+/v27XvHRqJz5865H8QjIyPp+PHjd4zneniVKlW8XgAAgLw+d4otm4M3kpOTqUGDBjR37txMp+Ggfe7cOfuwcuXK3O8THzBgAA0bNowWLVoktxxnz56l3bt30+jRo2ncuHFeLwAAgIoefvhhOWQlKChIJsY54XUQf/XVVykjI4Pat29PN2/elKUVXhAO4kOHDs3RwgAA5DaRg9I2N3KYzRwmjn88ZMf27dupdOnSVLx4cXrwwQflPseSJUvmbjmFs+/XXnuNrl69SocPH6Y9e/bQpUuXaNKkSd4+FQCApXZsxsTEyP1/jgOPyw4upSxbtoy2bNlC77zzDu3YsUNm7unp6Xlz2H1gYCDVrl07uw8HALBcJh4dHU0jR450GpfdLPyZZ56x/7tevXpUv359qlq1qszOudKRa0G8Xbt2WbbabN261dunBACwxEUhgnJQOrkbbgwJDw+XjSO5GsQbNmzodDstLY3i4uJkaaVPnz7ePh0AQJ4S+bPdm06fPk1XrlyhqKgorx7ndRCfPn262/Hjx4+npKQkb58OAEBJSUlJTu3Y8fHxMuEtUaKEHCZMmECPP/647E45ceIEjR07lqpVqyaPiPfLlX34XCrcdggAkJ+JPDpic9++fdSoUSM5MK6l87/feOMNCggIoEOHDtFjjz1GNWrUoP79+1OTJk3keam8Ldf47Hzi3CseHBxM+cHsHnX9vQiQh4o3G4LXWyd95ljimpRt27YlwzAyvX/jxo0+mY/XQbxHjx5Ot3kh+Ugj3urgYB8AyO9Efi2K51UQ575IRzabjWrWrEkTJ06kjh07+nLZAAB8zqZWDPcuiHMT+gsvvCB7GvkIIwAAq7EpFsS9Kg9xMZ6zbZytEAAgf/C6xl+3bl06efJk7iwNAEAuE7qfT5xP0MInu1q3bp3coZmYmOg0AADkZzbFruzjcU2cd1yOGjWKHnnkEXmb+xsdt0zcpcK3vT15CwBAXhL5NBjnehDno4sGDRpE27Zty90lAgDIp+dOsXQQN5vW27Rpk5vLAwCQq2w6r09+LewDAOjKqz5xPsb/boGcLxYBAJBfCaFxEOe6uOsRmwAAVmJTLIoX8PZKFHw9OAAAqxJqxXDPgzjq4QCgApuuQTyrUyoCAFiFTbFU3OMgnpGRkbtLAgAAXvPZRSEAAKxAqJWII4gDgF5sCOIAANYlSK0ojnIKAGjFplYMRxAHAL3YFAviqp0LBgBAKyinAIBWhGLtKQjiAKAVm1oxHEEcAPQiEMQBAKzLplgURzkFALRiUyuGozsFAMDKkIkDgFaEYpk4gjgAaMWGw+4BAKxLIBMHALAuG4I4AIB12RRLxXHuFAAAC8OOTQDQilArEUcQBwC92BSL4sjEAUArQq0YjiAOAHqxkVqQiQOAVoRiqbhqGyUAAK0gEwcArQhSC4I4AGjFplg5BUEcALQiSC0I4gCgFaFYFEcQBwCtCMWiOLpTAAAsDJk4AGjFRmpBEAcArQjFyikI4gCgFUFqQRAHAK0IxTJx1cpDAAB3DXrZHbwRGxtLXbp0oTJlysgNx5o1a5zuNwyD3njjDYqKiqKQkBDq0KEDHTt2zMu5IIgDAOSK5ORkatCgAc2dO9ft/VOnTqVZs2bRggUL6LvvvqNChQpRp06dKCUlxav5oJwCAFoReVROefjhh+XgDmfhM2bMoNdff526du0qxy1btowiIiJkxv7MM894PB+UUwBAKyIHQ2pqKiUmJjoNPM5b8fHxdP78eVlCMYWFhVHz5s1p9+7dXj0XgjgAaEWI7A8xMTEy2DoOPM5bHMAZZ96O+LZ5n6dQTgEArdhy0GQYHR1NI0eOdBoXFBRE/oQgDgBaETkoiXPA9kXQjoyMlH8vXLggu1NMfLthw4ZePRfKKQAAeaxy5coykG/ZssU+juvr3KXSokULr54LmTgAaEXk0TGbSUlJdPz4caedmXFxcVSiRAmqUKECDR8+nCZPnkzVq1eXQX3cuHGyp7xbt25ezQdBHAC0IvLogM19+/ZRu3bt7LfNWnqfPn1oyZIlNHbsWNlLPnDgQLp+/To98MADtGHDBgoODvZqPsLghkXFpNz29xJAXirebAhecI388cOcHD1+w5FL2X5s5zqlKL9BJg4AWhFqnToFQRwA9CIUC+LoTgEAsDCUUwBAK0KxM4ojiAOAVmxqxXAEcQDQi0AmDgBgXUKxTBw7NgEALAw1cQDQikA5BfKThR++T1s2fU3x8ScpKDiYGjZsRMNHjqZKlav4e9HAB0b360jdHmxANSpF0B+pafTdwZP02sy1dOy3i/L+ClEl6Oj6iW4f+9yYhfTvzT/gfXCBHZuQr+zb+z093fM5qlOvHqXfTqfZM9+jQQP607+/+IpCQ0P9vXiQQ60aV6MFq2Jp/5HfqECBAJowpAutmz+EGvWYTDdTbtHpC9eoUodop8f0e7wljejdgTZ+cwSvvwaZOM6dopirV69Su1YtaNHSj6hJ02akA53OnRJevDD9vvVt6tB/On1z4ITbaXavfIXifvmdXpqwglSU03On7Dp2LduPfaB6ccpvsGNTMUk3bsi/RcPC/L0okAuKFv7zDHfXEm66vb/RPeWpYa3ytHSNd9dp1InIwZAfIYgrJCMjg6a+M4UaNmpM1avX8PfiQC5cpX3a6Cfo2x9O0E8nzrmdpk+3FvTzyXO052A8Xn9N5Osg/vvvv1O/fv2ynMZXV59WwZTJE+jEsWM09d3p/l4UyAUzop+iOtWiqPeri93eHxxUkJ5+uCmy8LuwCZHtIT+y5ff67tKlS7Ocxt3Vp6e94/3Vp61uyuSJFLtjO324eClF/P/1+0Ad0195kh5pVZc6DZhFZy5edztN9w4NKTQ4kD5e932eL5+VCMXKKX7tE//iiy+yvP/kyZPZuvq0EeDfq0/nJb6mR8xbk2jrlk20cMlyKleuvL8XCXIhgD/2YAPqOGAm/Xb2SqbT9e12P32140e6fC0J70FW8ms0tmIQ52vJcZ0vq4sL8f3eXn1apyv7TJk0gf6zfh3NmD2PCoUWosuX/rxqSeEiRby+zBPkzxIKl0ieHPEBJSWnUETJInJ8QlIKpaSm2aerUj6cHmhclboNne/HpbUGoVgU92sQj4qKonnz5lHXrl3d3s8XFW3SpEmeL5eVfLJqpfzbv+/zTuMnTo6hrt17+GmpwFf++lRr+XfTP4c7jR/wxnL66Mvv7Lf7dG1BZy5cp827f8GLfxf5tLRtzSDOAXr//v2ZBvG7ZelAdPDIUbwMCgtp5FkP/JtzvpQD6MevQXzMmDHyas+ZqVatGm3bti1PlwkA1CZILX4N4q1atcry/kKFClGbNm3ybHkAQAOClIKzGAKAVoRiURxBHAC0ItSK4QjiAKAXQWrJ10dsAgBA1lBOAQC9CFIKgjgAaEUoFsURxAFAK0KtGI4gDgB6EaQWZOIAoBdBSkF3CgCAhSETBwCtCMVScQRxANCKUCuGI4gDgF4EqQWZOADoRZBSEMQBQCtCsSiO7hQAAAtDJg4AWhFqJeII4gCgF0FqQSYOAHoRpBQEcQDQilAsiiOIA4BWhFoxHN0pAABWhkwcALQiSC0I4gCgF0FKQRAHAK0IxaI4gjgAaEWoFcMRxAFAL4LUgnOnAABYGMopAKAXQUpBJg4A2u3YFNn8zxvjx48nIYTTUKtWLZ+vDzJxANCKyMNMvE6dOrR582b77QIFfB9yEcQBQCsiD+fFQTsyMjJX54FyCgDoF8VF9obU1FRKTEx0GnhcZo4dO0ZlypShKlWq0HPPPUenTp3y+eogiAMAeCgmJobCwsKcBh7nTvPmzWnJkiW0YcMGmj9/PsXHx1OrVq3oxo0b5EvCMAyDFJNy299LAHmpeLMheME18scPc3L0+N+uZJ45301k4T+zcUdBQUFyuJvr169TxYoV6b333qP+/fuTr6AmDgBaETkoinsasN0pVqwY1ahRg44fP06+hHIKAGhF5GDIiaSkJDpx4gRFRUWRLyGIA4B2mbjI5uCN0aNH044dO+jXX3+lb7/9lrp3704BAQHUs2dPn64PyikAoBmRJ3M5ffq0DNhXrlyhUqVK0QMPPEB79uyR//YlBHEAgFzwr3/9i/ICgjgAaEUodu4UBHEA0IogtSCIA4BWhGJRHEEcALQiFMvFEcQBQC+ClII+cQAAC0MmDgBaEaQWBHEA0IpQLIojiAOAVoRiuTiCOADoRZBSEMQBQCuC1ILuFAAAC0MmDgBaEYql4gjiAKAVoVhBBUEcALQi1IrhqIkDAFgZMnEA0IpAJg4AAPkFMnEA0IrAjk0AAOsSipVTkIkDgFYEqQVBHAD0IkgpOOweAMDCkIkDgFaEYqk4gjgAaEWoFcMRxAFAL4LUgkwcAPQiSCkI4gCgFaFYFEd3CgCAhSETBwCtCLUScRKGYRj+XgjIudTUVIqJiaHo6GgKCgrCS6o4vN9gQhBXRGJiIoWFhVFCQgIVLVrU34sDuQzvN5hQEwcAsDAEcQAAC0MQBwCwMARxRfDOzDfffBM7NTWB9xtM2LEJAGBhyMQBACwMQRwAwMIQxAEALAxBHADAwhDEFTF37lyqVKkSBQcHU/Pmzen777/39yJBLoiNjaUuXbpQmTJlSAhBa9asweusOQRxBaxatYpGjhwpWwwPHDhADRo0oE6dOtHFixf9vWjgY8nJyfL95Y02AEOLoQI4827WrBnNmTNH3s7IyKDy5cvT0KFD6dVXX/X34kEu4Ux89erV1K1bN7zGGkMmbnG3bt2i/fv3U4cOHezjbDabvL17926/LhsA5D4EcYu7fPkypaenU0REhNN4vn3+/Hm/LRcA5A0EcQAAC0MQt7jw8HAKCAigCxcuOI3n25GRkX5bLgDIGwjiFhcYGEhNmjShLVu22Mfxjk2+3aJFC78uGwDkPlxjUwHcXtinTx9q2rQp3XvvvTRjxgzZivbCCy/4e9HAx5KSkuj48eP22/Hx8RQXF0clSpSgChUq4PXWEFoMFcHthdOmTZM7Mxs2bEizZs2SrYeglu3bt1O7du3uGM8b8SVLlvhlmcC/EMQBACwMNXEAAAtDEAcAsDAEcQAAC0MQBwCwMARxAAALQxAHALAwBHEAAAtDEAcAsDAEcbCUvn37Ol0EoW3btjR8+HC/HDnJF2W4fv16ns8bwBGCOPgsuHJQ44FPylWtWjWaOHEi3b59O1df4X//+980adIkj6ZF4AUV4QRY4DOdO3emxYsXU2pqKq1fv54GDx5MBQsWpOjo6DuuRsSB3hf4xE8AOkMmDj4TFBQkz2FesWJFeumll+Ql4r744gt7CeStt96SV2mvWbOmnP7333+np556iooVKyaDcdeuXenXX3+1Px9fsYjP0Mj3lyxZksaOHUuGYTjN07WcwhuQV155RV5jlJeHfxEsXLhQPq954qjixYvLXwy8XOape2NiYqhy5coUEhIiL0T82WefOc2HN0o1atSQ9/PzOC4ngD8hiEOu4YDHWTfj85sfPXqUNm3aROvWraO0tDTq1KkTFSlShHbu3EnffPMNFS5cWGbz5mP+8Y9/yDPzLVq0iHbt2kVXr16VFwbOSu/evWnlypXyLI4///wzvf/++/J5Oah//vnnchpejnPnztHMmTPlbQ7gy5YtowULFtCRI0doxIgR1KtXL9qxY4d9Y9OjRw/q0qWLPO3riy++iAtQQ/5hAPhAnz59jK5du8p/Z2RkGJs2bTKCgoKM0aNHy/siIiKM1NRU+/TLly83atasKac18f0hISHGxo0b5e2oqChj6tSp9vvT0tKMcuXK2efD2rRpYwwbNkz+++jRo5ymy3m7s23bNnn/tWvX7ONSUlKM0NBQ49tvv3Watn///kbPnj3lv6Ojo43atWs73f/KK6/c8VwA/oCaOPgMZ9ic9XKWzSWKZ599lsaPHy9r4/Xq1XOqgx88eFBe3IAzcUcpKSl04sQJSkhIkNmy4znRCxQoIC984VpSMXGWzJeqa9OmjcfLzMtw8+ZNeuihh5zG86+BRo0ayX9zRu96bnZcNQnyCwRx8BmuFc+fP18Ga659c9A1FSpU6I4r1PBl5T7++OM7nqdUqVLZLt94i5eDffXVV1S2bFmn+7imDpDfIYiDz3Cg5h2JnmjcuDGtWrWKSpcuTUWLFnU7TVRUFH333XfUunVreZvbFffv3y8f6w5n+/wLgGvZvFPVlflLgHeYmmrXri2D9alTpzLN4O+55x65g9bRnj17PFpPgNyGHZvgF8899xyFh4fLjhTescnXiuQ+7pdffplOnz4tpxk2bBi9/fbbtGbNGvrll1/ob3/7W5YH11SqVElepqxfv37yMeZzfvLJJ/J+7prhrhQu+1y6dElm4VzOGT16tNyZuXTpUlnKOXDgAM2ePVveZoMGDaJjx47RmDFj5E7RFStW4FJokG8giINfhIaGUmxsrLy4L3d+cLbbv39/WRM3M/NRo0bR888/LwMz16A54Hbv3j3L5+VyzhNPPCEDfq1atWjAgAHyotGMyyUTJkyQnSURERE0ZMgQOZ4PFho3bpzsUuHl4A4ZLq9wyyHjZeTOFt4wcPshd7FMmTIl118jAE/gGpsAABaGTBwAwMIQxAEALAxBHADAwhDEAQAsDEEcAMDCEMQBACwMQRwAwMIQxAEALAxBHADAwhDEAQAsDEEcAICs6/8AGnVhkl3dnFIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Video Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Fake (0)       0.88      0.48      0.62        31\n",
      "    Real (1)       0.63      0.93      0.75        29\n",
      "\n",
      "    accuracy                           0.70        60\n",
      "   macro avg       0.76      0.71      0.69        60\n",
      "weighted avg       0.76      0.70      0.69        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "model_vid = load_model(\"saved_models/final_video_deepfake_model_xception.h5\")\n",
    "val_gen_vid = video_generator(os.path.join(VID_DIR), BATCH_SIZE_VID)\n",
    "\n",
    "def evaluate_video_model(model, generator, steps=None):\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    print(\"\\nStarting evaluation...\")\n",
    "\n",
    "    # Safely set steps (if not provided)\n",
    "    if steps is None:\n",
    "        try:\n",
    "            steps = len(generator)\n",
    "        except TypeError:\n",
    "            steps = 10  # fallback if it's a generator without len()\n",
    "\n",
    "    # Iterate through generator\n",
    "    for i, (X_batch, y_batch) in enumerate(generator):\n",
    "        preds = (model.predict(X_batch) > 0.5).astype(int)\n",
    "\n",
    "        # If y_batch is one-hot, convert it\n",
    "        if y_batch.ndim > 1 and y_batch.shape[-1] > 1:\n",
    "            y_batch = np.argmax(y_batch, axis=1)\n",
    "\n",
    "        y_true.extend(y_batch)\n",
    "        y_pred.extend(preds.flatten())\n",
    "\n",
    "        # Optional: break after given steps\n",
    "        if steps and i >= steps - 1:\n",
    "            break\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix - Video Model')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report (Video Model):\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Fake (0)', 'Real (1)']))\n",
    "\n",
    "# Call the function\n",
    "print(\"\\nEvaluating video model...\")\n",
    "evaluate_video_model(model_vid, val_gen_vid, steps=30)  # you can increase steps for larger evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf30a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 85s/step\n",
      "ğŸ¥ Prediction: Real (73.26% confidence)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Real', 0.7326409220695496)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load your trained model\n",
    "model_vid = tf.keras.models.load_model(\"saved_models/final_video_deepfake_model_xception.h5\")\n",
    "\n",
    "# Label mapping\n",
    "CLASS_NAMES = {0: \"Fake\", 1: \"Real\"}\n",
    "\n",
    "# Function to preprocess a frame\n",
    "def preprocess_frame(frame, target_size=(299, 299)):\n",
    "    frame = cv2.resize(frame, target_size)\n",
    "    frame = frame.astype(\"float32\") / 255.0\n",
    "    return frame\n",
    "\n",
    "# Function to predict a single video\n",
    "def predict_video(video_path, model, frame_sample_rate=10):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "\n",
    "    # Read frames from the video\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Sample every Nth frame to save memory\n",
    "        if frame_count % frame_sample_rate == 0:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = preprocess_frame(frame)\n",
    "            frames.append(frame)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        print(\" No frames read from video.\")\n",
    "        return None\n",
    "\n",
    "    frames = np.array(frames)\n",
    "    frames = np.expand_dims(frames, axis=0)  # Shape: (1, num_frames, H, W, C)\n",
    "\n",
    "    # Predict\n",
    "    pred = model.predict(frames)[0][0]\n",
    "\n",
    "    # label = 1 if pred > 0.5 else 0\n",
    "    # confidence = pred if label == 1 else 1 - pred\n",
    "    label = 0 if pred > 0.5 else 1  # flip labels\n",
    "    confidence = pred if label == 0 else 1 - pred\n",
    "\n",
    "\n",
    "    print(f\"ğŸ¥ Prediction: {CLASS_NAMES[label]} ({confidence*100:.2f}% confidence)\")\n",
    "    return CLASS_NAMES[label], float(confidence)\n",
    "\n",
    "# Example usage\n",
    "video_path = \"Dataset/Videos/real/15__outside_talking_pan_laughing.mp4\"  # change this to your video path\n",
    "predict_video(video_path, model_vid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7eae550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-6.28575012e-02],\n",
      "       [-2.06666276e-01],\n",
      "       [-1.61598669e-04],\n",
      "       [-9.45599601e-02],\n",
      "       [ 1.03239179e-01],\n",
      "       [-1.87157333e-01],\n",
      "       [ 4.61619236e-02],\n",
      "       [-5.98941837e-03],\n",
      "       [ 4.43395525e-02],\n",
      "       [-1.53854117e-01],\n",
      "       [ 1.39447628e-03],\n",
      "       [ 5.28368875e-02],\n",
      "       [ 2.66699586e-02],\n",
      "       [ 9.32395011e-02],\n",
      "       [ 9.10559297e-02],\n",
      "       [ 2.01126352e-01],\n",
      "       [ 1.38130888e-01],\n",
      "       [ 1.86126262e-01],\n",
      "       [-1.44252583e-01],\n",
      "       [ 1.37753084e-01],\n",
      "       [-2.99924379e-03],\n",
      "       [ 1.29937619e-01],\n",
      "       [-5.00621162e-02],\n",
      "       [-8.72180238e-02],\n",
      "       [ 3.16065662e-02],\n",
      "       [-2.71468842e-03],\n",
      "       [-8.65861848e-02],\n",
      "       [ 5.12877554e-02],\n",
      "       [ 6.83848783e-02],\n",
      "       [-9.59763527e-02],\n",
      "       [-1.02292620e-01],\n",
      "       [-5.75900860e-02],\n",
      "       [ 1.14152573e-01],\n",
      "       [-1.70300417e-02],\n",
      "       [ 2.32614903e-03],\n",
      "       [ 1.60780668e-01],\n",
      "       [ 9.51315165e-02],\n",
      "       [ 5.70479035e-02],\n",
      "       [ 1.19870074e-01],\n",
      "       [ 1.30629003e-01],\n",
      "       [ 5.37127107e-02],\n",
      "       [ 1.11609995e-01],\n",
      "       [ 1.74557999e-01],\n",
      "       [ 9.73610133e-02],\n",
      "       [-5.26037253e-02],\n",
      "       [ 5.08994516e-03],\n",
      "       [-1.60137698e-01],\n",
      "       [ 1.64451256e-01],\n",
      "       [-1.08695216e-01],\n",
      "       [ 1.94641292e-01],\n",
      "       [ 4.51403148e-02],\n",
      "       [-6.18685689e-03],\n",
      "       [ 1.36929750e-01],\n",
      "       [-5.72831519e-02],\n",
      "       [-1.24461994e-01],\n",
      "       [ 6.50841445e-02],\n",
      "       [-6.10111691e-02],\n",
      "       [-1.59382418e-01],\n",
      "       [-1.82148978e-01],\n",
      "       [ 1.84806604e-02],\n",
      "       [ 1.17170565e-01],\n",
      "       [-1.77288368e-01],\n",
      "       [-9.54250842e-02],\n",
      "       [-2.09462922e-02],\n",
      "       [ 7.22769424e-02],\n",
      "       [ 5.03762290e-02],\n",
      "       [-2.58836169e-02],\n",
      "       [-8.48726705e-02],\n",
      "       [-9.16570127e-02],\n",
      "       [-8.06797743e-02],\n",
      "       [ 1.37527525e-01],\n",
      "       [-3.51832062e-02],\n",
      "       [ 8.54423642e-03],\n",
      "       [-1.86438054e-01],\n",
      "       [-6.18806183e-02],\n",
      "       [-3.85668222e-03],\n",
      "       [-8.66343230e-02],\n",
      "       [-1.72738522e-01],\n",
      "       [ 1.14027597e-01],\n",
      "       [-1.70768306e-01],\n",
      "       [ 5.75325117e-02],\n",
      "       [ 1.86202392e-01],\n",
      "       [-1.68652490e-01],\n",
      "       [ 1.95992857e-01],\n",
      "       [ 1.05330676e-01],\n",
      "       [ 1.45492017e-01],\n",
      "       [ 1.49456114e-02],\n",
      "       [ 1.72252789e-01],\n",
      "       [ 7.54508302e-02],\n",
      "       [-1.93398982e-01],\n",
      "       [-3.75580452e-02],\n",
      "       [ 7.57437497e-02],\n",
      "       [-1.87780112e-01],\n",
      "       [ 1.54721603e-01],\n",
      "       [-1.24105841e-01],\n",
      "       [-2.03113392e-01],\n",
      "       [-1.48078457e-01],\n",
      "       [ 1.18330896e-01],\n",
      "       [ 1.05995543e-01],\n",
      "       [-1.12305634e-01],\n",
      "       [-1.39150128e-01],\n",
      "       [-1.83746621e-01],\n",
      "       [ 8.33573844e-03],\n",
      "       [-1.29673064e-01],\n",
      "       [-1.16081191e-02],\n",
      "       [-1.48042142e-02],\n",
      "       [ 9.97021571e-02],\n",
      "       [ 1.44347325e-01],\n",
      "       [ 7.28299748e-03],\n",
      "       [ 1.10310175e-01],\n",
      "       [ 8.52653906e-02],\n",
      "       [-8.51266459e-02],\n",
      "       [-1.14764981e-01],\n",
      "       [ 1.56424761e-01],\n",
      "       [ 1.03935413e-01],\n",
      "       [-8.30682442e-02],\n",
      "       [ 1.30218074e-01],\n",
      "       [-7.58931562e-02],\n",
      "       [ 5.77811264e-02],\n",
      "       [-2.10340217e-01],\n",
      "       [-1.26608253e-01],\n",
      "       [-1.08778708e-01],\n",
      "       [ 8.50725025e-02],\n",
      "       [ 1.30544901e-01],\n",
      "       [-4.87506948e-02],\n",
      "       [ 4.72636297e-02],\n",
      "       [-7.21938685e-02],\n",
      "       [ 1.75363570e-01]], dtype=float32), array([0.00539071], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(model_vid.layers[-1].get_weights())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ade7e7",
   "metadata": {},
   "source": [
    "-ve values shows Fake favoured prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dc86d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: (None, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ time_distributed_1              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,114,624</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ time_distributed_1              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2048\u001b[0m)       â”‚    \u001b[38;5;34m20,861,480\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mTimeDistributed\u001b[0m)               â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚     \u001b[38;5;34m1,114,624\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m16,512\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m129\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,992,747</span> (83.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,992,747\u001b[0m (83.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,131,265</span> (4.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,131,265\u001b[0m (4.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> (79.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,861,480\u001b[0m (79.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary None\n"
     ]
    }
   ],
   "source": [
    "print(\"Model output shape:\", model_vid.output_shape)\n",
    "print(\"Model Summary\",model_vid.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
